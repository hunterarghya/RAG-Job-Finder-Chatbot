# RAG Chatbot for finding jobs

A lightweight RAG-based chatbot that:

- Scrapes job listings from Indeed and Naukri
- Embeds resume + job descriptions into a vector database
- Matches the best jobs for a candidate
- Provides conversational insights using Groq LLMs
- Automatically monitors new jobs and notifies users via email when high-fit roles appear

Purpose of the Application:

A unified job-search platform that **automatically scrapes jobs from multiple portals like LinkedIn, Indeed, Naukri etc** , centralizes them in one dashboard, and uses an **AI chatbot** to **analyze your resume**, recommend the **best-fit roles** according to the skills in the resume or the user's **personal preferences**, and highlight **missing skills** or **market demands**â€”so you don't need to visit multiple sites or read every job description manually.
Additionally, the system can **run automated background job searches on a schedule (daily / weekly)** and proactively notify users when strong matches are found, removing the need for manual searching altogether.

ğŸš€ **Demo:** [Watch a demo](https://drive.google.com/file/d/18omur_TgE-z8Go6iHtZmHfMKxK9SpGbB/view?usp=sharing)

---

## âœ¨ Features

### ğŸ” Authentication

- User Registration & Login
- JWT-based authentication
- Secure password hashing
- Protected endpoints

### ğŸ§  AI-Driven Job Matching

- Resume uploaded â†’ automatically extracted, chunked & embedded
- Scraped jobs â†’ chunked & embedded
- ChromaDB stores all embeddings for similarity search
- LLM chatbot evaluates:
  - Jobâ€“resume match score
  - Missing skills
  - Fit analysis across all scraped jobs

### ğŸ•¸ï¸ Web Scraping (Indeed and Naukri)

- Automated job scraping using:
  - BeautifulSoup
  - Selenium + WebDriver Manager
- Extracts:
  - Title
  - Company
  - Location
  - Salary
  - Full job description
  - Apply link

### ğŸ“„ Resume Processing

- Accepts PDF uploads
- Text extraction using:
  - PyMuPDF
  - PyPDF
- Automatic preprocessing + splitting
- Vector embedding with Sentence Transformers

### â° Automated Job Monitoring

- Users can schedule automatic job scraping:
  - **Off**
  - **Daily**
  - **Weekly**
- Scheduler runs in the background using **Celery + Redis**
- Each scheduled run:
  - Scrapes new jobs based on user-defined title and location
  - Matches jobs against resume embeddings
  - Computes similarity scores
  - Sends an **email notification** when a job exceeds a fit threshold (e.g. â‰¥ 0.6)
- Fully async and non-blocking for the main API

### ğŸ—„ï¸ Database

MongoDB stores:

- User accounts
- User resumes
- Scraped jobs (full descriptions, links, metadata)

ChromaDB stores:

- Embeddings for jobs
- Embeddings for resumes
- Used for similarity search during AI analysis

### ğŸ’¬ Chatbot

- Powered by LLM via Groq API
- Answers smart queries like:

  - _â€œWhich of the newly scraped jobs are best for me?â€_
  - _â€œWhat should I improve in my resume?â€_
  - _â€œCompare my resume to the job requirements.â€_

  ### ğŸ“§ Email Notifications

- Triggered automatically by background workers
- Sent when a job exceeds a similarity threshold
- Includes:
  - Job title
  - Company
  - Match score
  - Apply link
- Delivered to the userâ€™s registered email address

### ğŸ–¥ï¸ UI

- Upload resume
- View upload success state
- View scraped jobs
- Click to open full job description in modal
- Chat interface for job-matching queries

---

## âš™ï¸ Tech Stack

- **FastAPI** â€“ Backend web framework
- **Python** â€“ Core backend language
- **OAuth2 + JWT Auth** â€“ Secure authentication (OAuth2PasswordBearer with JWT tokens)
- **MongoDB (PyMongo)** â€“ Database for users, resumes & scraped jobs
- **ImageKit** â€“ External storage for resume pdf's
- **ChromaDB** â€“ Vector database for semantic search
- **Sentence Transformers** â€“ Embedding model for resume + job descriptions
- **LangChain Text Splitters** â€“ Chunking for RAG pipeline
- **PyMuPDF & PyPDF** â€“ Resume text extraction
- **Selenium + BeautifulSoup** â€“ Job scraping from Indeed and Naukri
- **Groq LLM API** â€“ Fast LLM inference for chatbot responses
- **Celery** â€“ Distributed background task processing
- **Redis** â€“ Message broker & scheduler backend
- **Celery RedBeat** â€“ Persistent periodic task scheduler
- **Uvicorn** â€“ ASGI server
- **Docker & Docker Compose** â€“ Redis & Celery services

---

## ğŸš€ How to Run

### 1ï¸âƒ£ Clone the repository

```bash
git clone <repo-url>
cd RAG-Job-Finder-Chatbot
```

### 2ï¸âƒ£ Create a virtual environment

```bash
py -3.10 -m venv .venv
source .venv/bin/activate      # Linux / Mac
.venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set up environment variables

Set up your environment varialbles in `.env` as in `env_example.txt`

### 5ï¸âƒ£ Set up Celery & Redis services

These services are required for scheduled job scraping and email notifications.

#### ğŸ”¹ Start Redis (Docker)

Open a new terminal (terminal 2).

```bash
cd RAG-Job-Finder-Chatbot
docker compose up --build
```

#### ğŸ”¹ Start Celery Worker

Open another new terminal (terminal 3).

```bash
cd RAG-Job-Finder-Chatbot

.venv\Scripts\activate         # Windows
# or
source .venv/bin/activate      # Linux / Mac

set PYTHONPATH=.               # Windows
# or
export PYTHONPATH=.            # Linux / Mac

celery -A worker.app worker --loglevel=info --pool=solo

```

### 5ï¸âƒ£ Run the server (from the first terminal)

```bash
uvicorn api.main:app --reload
```

Visit:  
ğŸ‘‰ **http://127.0.0.1:8000**

---

## ğŸ§ª Example Usage

### âœ” Register User

**POST** `/register`

### âœ” Login User

**POST** `/login`  
Returns JWT token.

### âœ” Scrape Jobs

**POST** `/scrape`  
Scrapes from Indeed and Naukri and stores full job data.

### âœ” Configure the scheduler

**POST** `/schedule-scraper`

- Parameters:

  - Job title
  - Location
  - Frequency: off | daily | weekly

- Creates or updates a background scheduled task

### âœ” Upload Resume

**POST** `/upload_resume`  
Stores + embeds resume in ChromaDB.

### âœ” Get All Jobs

**GET** `/jobs`

### âœ” AI Chat

**POST** `/chat`  
Send query â†’ get intelligent job-matching response.

---

## ğŸ‘¤ Author

**Arghya Malakar**  
ğŸ“§ arghyaapply2016@gmail.com  
ğŸŒ GitHub: https://github.com/hunterarghya
